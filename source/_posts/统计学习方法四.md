---
title: 【统计学习方法】4-朴素贝叶斯法分类
date: 2021-01-27 10:26:35
categories:
	- 机器学习
tags:
	- 统计学习方法
---

一句话介绍：对给定的输入x，结合贝叶斯概率理论，通过学习到的模型，将**后验概率最大的类**作为x的类输出。

------

最好学习过贝叶斯估计方法。

在本科阶段的**概率论**或研究生阶段的**数理统计**中，都有对贝叶斯估计方法的介绍，与其他估计方法的最大不同是——加入了**先验估计**概念。

# 基础知识

部分公式：

- **先验概率分布$P(Y=c_k),k=1,2,...,K$**
- **条件概率分布**$P(X=x|Y=c_k)=P(X^{(1)}=x^{(1)},...,X^{(n)}=x^{(n)}|Y=c_k),k=1,2,...,K$
- **后验概率分布（贝叶斯定理）$P(Y=c_k|X=x)=\frac{P(X=x|Y=c_k)P(Y=c_k)}{\Sigma_k P(X=x|Y=c_k)P(Y=c_k)}$**

**补充一个忽略了很久的知识点：**

**arg max(f(x)) 函数：**得到的结果是使得 f(x)取得最大值所对应的变量点x(或x的集合)。arg即argument，自变量。

<!-- more -->

首先有一个**训练数据集**$T=\{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\}$，是由**X**和**Y**的联合概率分布$P(X,Y)$独立同分布产生。

 **【需要注意的是，这个联合概率分布是用朴素贝叶斯法训练出来的】**

在朴素贝叶斯法中，对条件概率分布做了**条件独立性的假设：**

$P(X=x|Y=c_k) = P(X^{(1)}=x^{(1)},...,X^{(n)}=x^{(n)}|Y=c_k) = \prod_{j=1}^n P(X^{(j)}=x^{(j)}|Y=c_k)$

那么，朴素贝叶斯法分类的基本公式就是

$P(Y=c_k|X=x)=\frac{P(Y=c_k)\prod_j P(X^{(j)}=x^{(j)}|Y=c_k)}{\Sigma_k P(Y=c_k)\prod_j P(X^{(j)}=x^{(j)}|Y=c_k)},k=1,2,...,K$

**分母都是相同的，只考虑分子即可，**选择分子最大的那个就是概率最大的，也就是后验概率最大的类了：

$y=arg\ max_{c_k}{P(Y=c_k)\prod^n_{j=1} P(X^{(j)}=x^{(j)}|Y=c_k)}$

------

以上内容确实就是**朴素贝叶斯学习和分类算法**的全部了，但是想必还是不太好理解。

一方面，**先验分布和条件分布假设**可能需要使用极大似然估计的方法求取，或者使用贝叶斯估计的方法求取，这又是好几个公式。

另一方面，还不如直接看一个例子！

------

# 举个栗子!

我们有一个训练数据集：

|           | 1    | 2    | 3    | 4    | 5    | 6    | 7    | 8    | 9    | 10   | 11   | 12   | 13   | 1    |      |
| :-------- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| $X^{(1)}$ | 1    | 1    | 1    | 1    | 1    | 2    | 2    | 2    | 2    | 2    | 3    | 3    | 3    | 3    | 3    |
| $X^{(2)}$ | $S$  | $M$  | $M$  | $S$  | $S$  | $S$  | $M$  | $M$  | $L$  | $L$  | $L$  | $M$  | $M$  | $L$  | $L$  |
| $Y$       | -1   | -1   | 1    | 1    | -1   | -1   | -1   | 1    | 1    | 1    | 1    | 1    | 1    | 1    | -1   |

这个数据集是什么意思呢？

$X^{(1)}$和$X^{(2)}$是特征。

- $X^{(1)}$ 取值集合是$A_1={1,2,3}$
- $X^{(2)}$ 取值集合是$A_2={S,M,L}$

$Y$ 就是类标记了，两个类，1和-1.

**现在的目的是，学习一个朴素贝叶斯分类器，并且确定 $x=(2,S)^T$ 的类标记 $y$ 是多少？**

开始计算一堆概率：

$P(Y=1)=\frac{9}{15},P(Y=-1)=\frac{6}{15}$

$P(X^{(1)}=1|Y=1)=\frac{2}{9},P(X^{(1)}=2|Y=1)=\frac{3}{9},P(X^{(1)}=3|Y=1)=\frac{4}{9}$

其实还是挺好算的，就是有点多，要把先验概率和条件概率全部算完：

$P(X^{(2)}=S|Y=1)=\frac{1}{9},P(X^{(2)}=M|Y=1)=\frac{4}{9},P(X^{(2)}=L|Y=1)=\frac{4}{9}$

$P(X^{(1)}=1|Y=-1)=\frac{3}{6},P(X^{(1)}=2|Y=-1)=\frac{2}{6},P(X^{(1)}=3|Y=-1)=\frac{1}{6}$

$P(X^{(2)}=S|Y=-1)=\frac{3}{6},P(X^{(2)}=M|Y=-1)=\frac{2}{6},P(X^{(2)}=L|Y=-1)=\frac{1}{6}$

那么接下来根据**朴素贝叶斯分类**的**基本公式**，我们就是要看**$x=(2,S)^T$的后验概率在哪一类（y=1还是-1）的条件下更大，**我们**只计算分子即可：**

**这里很明显，目标的特征是：$X^{(1)}=2,X^{(2)}=S$**

​    $P(Y=1)P(X^{(1)}=2|Y=1)P(X^{(2)}=S|Y=1)=\frac{9}{15} \cdot \frac{3}{9}\cdot\frac{4}{9}=\frac{1}{45}$

​    $P(Y=-1)P(X^{(1)}=2|Y=-1)P(X^{(2)}=S|Y=-1)=\frac{6}{15} \cdot \frac{2}{6}\cdot\frac{3}{6}=\frac{1}{15}$

**经过计算，Y=-1的情况概率更大，所以y=-1.**



非常典型的贝叶斯概率估计。

这一页的公式确实打的很费劲。